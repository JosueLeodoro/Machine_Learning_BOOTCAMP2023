{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORTANDO BIBLIOTECAS"
      ],
      "metadata": {
        "id": "vGXh-Exi1Myi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "FS2ewPkU1A1A"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch #framework procurar posteriormente\n",
        "import torch.nn.functional as F #funções para redes neurais\n",
        "import torchvision #biblioteca para visao computacional\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time #tempo para algoritmo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORTANDO DO MNIST"
      ],
      "metadata": {
        "id": "cLsoqeG-Bo3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor() #definindo a conversão de imagem para Tensor (tensorflow)\n",
        "\n",
        "trainset = datasets.MNIST('./MNIST_data/', download=True, transform=transform) # Carrega a parte de treino do dataset\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) #Cria um buffer para pegar os dados por partes\n",
        "\n",
        "valset = datasets.MNIST('./MNIST_data/', download=True, train=False, transform=transform) #carrega a parte de validação\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True) #cria um bufer para pegar os dados por partes\n"
      ],
      "metadata": {
        "id": "Wbp3cUUp1ET0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainloader)\n",
        "imagens, etiquetas = next(dataiter) #funçao fornecida dataiter.next(), porém atualmente a funçao next não é mais chamada desta forma, logo a solução é reformular como chamar a funçao next\n",
        "plt.imshow(imagens[0].numpy().squeeze(), cmap='gray_r');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "ocRkauXT2pmd",
        "outputId": "dec925b4-e50f-4322-da81-0d85a27840ae"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(imagens[0].shape) #para verificar as dimensões do tensor de cada imagem\n",
        "print(etiquetas[0].shape) #para verificar a dimensão do tensor de cada etiqueta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAXeT71z3aS7",
        "outputId": "081bf2cb-2a91-4b06-edab-fe5c71952641"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "torch.Size([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#indo atras do inception atraves do site https://keras.io/api/applications/inceptionv3/\n",
        "# inception v3 utilizado pelo facebook para reconhecimento facial\n",
        "\n",
        "class Modelo(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Modelo, self).__init__()\n",
        "        self.linear1 = nn.Linear(28*28, 128) #camada de entrada, 784 neuronios que se ligam a 128\n",
        "        self.linear2 = nn.Linear(128, 64) # camada interna 1, 128 neuronios que se ligam a 64\n",
        "        self.linear3 = nn.Linear(64, 10) # camada interna 2, 64 neuronios que se ligam a 10\n",
        "        # para a camada de saída nao é necessario definir nada pois so precisamos pegar o output da camada interna 2\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.linear1(X)) # funcao de ativacao da camada de entrada para a camada interna 1\n",
        "        x = F.relu(self.linear2(X)) # funcao de ativacao da camada interna 1 para a camada interna 2\n",
        "        x = self.linear3(X) # funcao de ativacao da camada interna 2 para a camada de saida, nesse caso f(x) = x\n",
        "        return F.log_softmax(X, dim=1) # dados utilizados para calcular a perda"
      ],
      "metadata": {
        "id": "dLc6co5R41C7"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def treino(modelo, trainloader, device):\n",
        "\n",
        "    otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5) #define a politica de atualizacao dos pesos e da bias\n",
        "    inicio - time() #timer para sabermos quanto tempo levou o treino\n",
        "\n",
        "    criterio = nn. NLLLoss() #definindo o criterio para calcular a perda\n",
        "    EPOCH = 10 #numero de epochs que o algoritmo rodará (epocas)\n",
        "    modelo.train() #ativando o modo de treinamento do modelo\n",
        "\n",
        "    for epoch in range(EPOCH):\n",
        "        perda_acumulada = 0 #inicialização da perda acumulada da epoch em questao\n",
        "\n",
        "        for imagens, etiquetas in trainloader:\n",
        "\n",
        "            imagens = imagens.view(imagens.shape[0], -1) #convertendo as imagens para \"vetores\" de 28*28 casas para\n",
        "            otimizador.zero_grad() # zerando os gradientes por conta do ciclo anterior\n",
        "\n",
        "            output = modelo(imagens.to(device)) # colocando os dados no modelo\n",
        "            perda_instantanea = criterio(output, etiquetas.to(device)) # calculando a perda da epoch em questao\n",
        "\n",
        "            perda_instantanea.backward() # back propagation a partir da perda\n",
        "\n",
        "            otimizador.step() #atualizando os pesos e a bias\n",
        "\n",
        "            perda_acumulada += perda_instantanea.item() #atualizacao da perda acumulada\n",
        "\n",
        "        else:\n",
        "            print(\"Epoch {} - Perda resultante: {}\".format(epoch+1, perda_acumulada/len(trainloader))) #printando a epoca e a perda resultante\n",
        "    print(\"\\nTempo de treino (em minutos) =\", (time()-inicio/60))\n"
      ],
      "metadata": {
        "id": "6gsZh65t7Vuh"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validacao(modelo, valloader, device):\n",
        "    conta_corretas, conta_todas = 0, 0\n",
        "    for imagens, etiquetas in valloader:\n",
        "        for i in range(len(etiquetas)):\n",
        "            img = imagens[i].view(1, 784)\n",
        "            #desativar o autograd para acelerar a validacao. Grafos computacionais dinamicos tem um custo alto de processamento\n",
        "            with torch.no_grad():\n",
        "                logps = modelo(img.to(device)) #output do modelo em escala logaritmica\n",
        "\n",
        "            ps = torch.exp(logps) #converte output para escala normal (lembrando que é um tensor)\n",
        "            probab = list(ps.cpu().numpy()[0])\n",
        "            etiqueta_pred = probab.index(max(probab)) # converte o tensor em um numero, no caso, o numero que o modelo previu\n",
        "            if (etiqueta_certa == etiqueta_pred): #compara a previsao com o valor correto\n",
        "                conta_corretas += 1\n",
        "            conta_todas\n",
        "\n",
        "    print(\"Total de imagens testadas = \", conta_todas)\n",
        "    print(\"\\n Precisão do modelo = {}%\".format(conta_corretas*100/conta_todas))"
      ],
      "metadata": {
        "id": "zHYXDiws-qhM"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = Modelo()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #verificando se tem cuda disponivel para gpu\n",
        "modelo.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwDHTJQYATQm",
        "outputId": "213f128f-3df9-4918-8791-708ff835b691"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Modelo(\n",
              "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jUYS4Y3eBV7F"
      },
      "execution_count": 33,
      "outputs": []
    }
  ]
}